---
title: "SAT and College Grades"
author: "Olivia Chang"
date: 2023-04-18
output:
  github_document:
    toc: true
prerequisites:
  - e-vis00-basics
---

*Purpose*: How do we apply hypothesis testing to investigating data? In this challenge you'll practice using hypothesis testing tools to make sense of a dataset.

*Reading*:
- [Harvard Study Says SATs Should Be Optional: Here's Why](https://www.csmonitor.com/USA/USA-Update/2016/0120/Harvard-study-says-SATs-should-be-optional.-Here-s-why) (Optional); easy-to-read news article on colleges going SAT-free
- [Norm-Referenced Tests and Race-Blind Admissions](https://cshe.berkeley.edu/publications/norm-referenced-tests-and-race-blind-admissions-case-eliminating-sat-and-act-university) (Optional); technical report on relationship between the SAT/ACT and non-academic factors

*Credit*: This is based on a [case study](http://onlinestatbook.com/2/case_studies/sat.html) originally prepared by Emily Zitek, with data collected through the research of Thomas MacFarland.

```{r setup}
library(tidyverse)
library(readxl)
library(broom)
library(modelr)
library(rsample)
```

<!-- include-rubric -->
# Grading Rubric
<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics define how you will be graded, both on an individual and team basis.

## Individual
<!-- ------------------------- -->

| Category | Needs Improvement | Satisfactory |
|----------|----------------|--------------|
| Effort | Some task __q__'s left unattempted | All task __q__'s attempted |
| Observed | Did not document observations, or observations incorrect | Documented correct observations based on analysis |
| Supported | Some observations not clearly supported by analysis | All observations clearly supported by analysis (table, graph, etc.) |
| Assessed | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support |
| Specified | Uses the phrase "more data are necessary" without clarification | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability | Code sufficiently close to the [style guide](https://style.tidyverse.org/) |

## Due Date
<!-- ------------------------- -->

All the deliverables stated in the rubrics above are due **at midnight** before the day of the class discussion of the challenge. See the [Syllabus](https://docs.google.com/document/d/1qeP6DUS8Djq_A0HMllMqsSqX3a9dbcx1/edit?usp=sharing&ouid=110386251748498665069&rtpof=true&sd=true) for more information.

*Background*: Every year about 2 million students take the Scholastic Aptitude Test (SAT). The exam is [controversial](http://www.nea.org/home/73288.htm) but [extremely consequential](https://www.csmonitor.com/2004/0518/p13s01-legn.html). There are many claims about the SAT, but we're going to look at just one: Is the SAT predictive of scholastic performance in college? It turns out this is a fairly complicated question to assess---we'll get an introduction to some of the complexities.

# Obtain the Data
<!-- -------------------------------------------------- -->

### __q1__ Visit the [SAT and College GPA](http://onlinestatbook.com/2/case_studies/sat.html) case study page, scroll to the bottom, and click the `Open Data with Excel` button. This will allow you to download an `xls` file. Save the file to your `data` folder, load the data as `df_sat`, and perform your "first checks" against these data. Answer the questions below:

```{r q1-task}
filename_sat <- "data/sat.xls"
df_sat <-
  read_xls(
    filename_sat,
    col_names = TRUE
  )

## TODO: Do your "first checks"
df_sat
df_sat %>% summary()
df_sat %>% glimpse()


```

**Observations**:

- Fill in the following "data dictionary"

| Column     | Meaning |
|------------|---------|
| `high_GPA` | high school GPA         |
| `math_SAT` | math SAT score          |
| `verb_SAT` | verbal SAT score        |
| `comp_GPA` | computer science GPA    |
| `univ_GPA` | overall university GPA  |

- What information do we have about these students?
  - We have the high school GPA and SAT scores of these students as well as their overall GPA in college, and the GPA of their computer science coursework
- What kinds of information *do we not have* about these students?
  - We don't know their social or economic background - are they first gen/low income? Are they white, Asian, Black, Latino? Did their parents go to college? Did they have prior experience in computer science?
- Based on these missing variables, what possible effects could be present in the data that we would have *no way of detecting*?
  - The dataset is of students who went to a state university with a BS in computer science. CS selects for a specific type of student and its possible that high school GPA predicts college GPA uniquely well for CS students - we just don't know. We also have no idea if factors like race, gender, economic status affect the results.

# Analysis with Hypothesis Testing
<!-- ----------------------------------------------------------------------- -->

We're going to use two complementary approaches to analyze the data, the first based on hypothesis testing of correlation coefficients, and the second based on fitting a regression model and interpreting the regression coefficients.

To simplify the analysis, let's look at a composite SAT score:

```{r compute-composite}
## NOTE: No need to edit this
df_composite <-
  df_sat %>%
  mutate(both_SAT = math_SAT + verb_SAT)
```

## View 1: Correlations
<!-- ----------------------------------------------------------------------- -->

### __q2__ Create a *single* plot that shows `univ_GPA` against *both* `high_GPA` and `both_SAT`. Visually compare the two trends.

*Hint*: One way to do this is to first *pivot* `df_composite`.

```{r q2-task}
conversion <- 1600/4
## TODO:
df_composite %>%
  # select(c("univ_GPA", "high_GPA", "both_SAT")) %>%
  # pivot_longer(
  #   cols = c("high_GPA", "both_SAT"),
  #   names_to = c("type", "test"),
  #   names_sep = "_",
  #   values_to = "value"
  # ) %>%
  # ggplot() +
  #   geom_point(mapping = aes(x = univ_GPA, y = value, color = test))
  ggplot(aes(x = univ_GPA)) +
    geom_point(aes(y = high_GPA), color = "black") +
    geom_point(aes(y = both_SAT / (conversion)), color = "red") +
  scale_y_continuous(name = "High School GPA", sec.axis = sec_axis(name = "SAT Score", trans = ~.*conversion)) +
  theme(axis.title.y = element_text(color = "black"), axis.title.y.right = element_text(color = "red")) +
  xlab("University GPA")
  
```

**Observations**:

- What relationship do `univ_GPA` and `both_SAT` exhibit?
  - univ_GPA and both_SAT have a positive correlation
- What relationship do `univ_GPA` and `high_GPA` exhibit?
  - univ_GPA and high_GPA have a positive correlation

### Hypothesis Testing with a Correlation Coefficient
<!-- ------------------------- -->

We can use the idea of hypothesis testing with a correlation coefficient. The
idea is to set our null hypothesis to the case where there is no correlation,
and test to see if the data contradict that perspective. Formally, the null (H0)
and alternative (HA) hypotheses relating to a correlation coefficient between
two variables `X, Y` are:

$$\text{H0: } \text{Corr}[X, Y] = 0$$

$$\text{HA: } \text{Corr}[X, Y] \neq 0$$

The R function `cor.test` implements such a hypothesis test under the assumption that `X, Y` are both normally distributed. First, let's check to see if this assumption looks reasonable for our data.

### __q3__ Plot histograms for `both_SAT, high_GPA, univ_GPA`. Which---if any---of the variables look approximately normally distributed.

```{r q3-task}
df_composite %>%
  ggplot() +
    geom_histogram(aes(both_SAT))

df_composite %>%
  ggplot() +
    geom_histogram(aes(high_GPA))

df_composite %>%
  ggplot() +
    geom_histogram(aes(univ_GPA))
```

**Observations**:

- To what extent does `both_SAT` look like a normal distribution?
  - There appears to be more values centered around 1200 but it doesn't appear to be truly a normal distribution.
- To what extent does `high_GPA` look like a normal distribution?
  - It almost appears to be a normal distribution but the data appears to be skewed slightly left.
- To what extent does `univ_GPA` look like a normal distribution?
  - It doesn't look normally distributed as there are data points centered around 2.25 and then many data points centered around approximately 3.4.

Keep in mind your findings as you complete q4.

### __q4__ Use the function `cor.test()` to construct confidence intervals for `corr[high_GPA, univ_GPA` and `corr[both_SAT, univ_GPA]`. Answer the questions below.

```{r q4-task}
## TODO: Use the function cor.test() to test the correlations between
##       high_GPA and univ_GPA, as well as between
##       both_SAT and univ_GPA

cor.test(df_composite$univ_GPA, df_composite$high_GPA)

cor.test(df_composite$univ_GPA, df_composite$both_SAT)
```

**Observations**:

- Which correlations are significantly nonzero?
  - Both the university GPA and high school GPA correlation and university GPA and SAT score correlation are significantly nonzero.
- Which of `high_GPA` and `both_SAT` seems to be more strongly correlated with `univ_GPA`?
  - High school GPA is more strongly correlated with university GPA.
- How do the results here compare with the visual you created in q2?
  - The visual in q2 suggests a positive correlation between univ_GPA and high_GPA, and univ_GPA and both_SAT, and that the relationship between high school GPA and university GPA is more linear (and more strongly correlated) than university GPA and SAT scores, so the results here make sense.
- Based on these results, what can we say about the predictive capabilities of both `high_GPA` and `both_SAT` to predict `univ_GPA`?
  - high_GPA and both_SAT are able to make moderately accurate predictions about university GPA, but high_GPA is better able to predict university GPA.

Finally, let's use the bootstrap to perform the same test using *different* assumptions.

### __q5__ Use the bootstrap to approximate a confidence interval for `corr[high_GPA, univ_GPA`. Compare your results---both the estimate and confidence interval---to your results from q4.

```{r q5-task}
## TODO: Use the bootstrap to compute a confidence interval for corr[high_GPA, univ_GPA]
df_q5 <- df_composite %>%
  bootstraps(times = 1000) %>%
  mutate(
    estimates = map(
      splits,
      ~ analysis(.x)
    )
  ) %>%
  unnest(estimates)

cor.test(df_q5$high_GPA, df_q5$univ_GPA)
```

**Observations**:

- How does your estimate from q5 compare with your estimate from q4?
  - The correlation is approximately the same
- How does your CI from q5 compare with your CI from q4?
  - The confidence interval is much smaller/tighter

*Aside*: When you use two different approximations to compute the same quantity and get similar results, that's an *encouraging sign*. Such an outcome lends a bit more credibility to the results.

## View 2: Modeling
<!-- ------------------------- -->

Correlations are useful for relating two variables at a time. To study the relationship among more variables we can instead use a fitted model. Using a model, we can also help assess whether it is *worthwhile* to measure a variable.

To begin, let's first split the data into training and validation sets.

```{r split}
## NOTE: No need to edit
set.seed(101)

df_train <-
  df_composite %>%
  rowid_to_column() %>%
  slice_sample(n = 80)

df_validate <-
  df_composite %>%
  rowid_to_column() %>%
  anti_join(
    .,
    df_train,
    by = "rowid"
  )
```

### Hypothesis Testing with a Model
<!-- ------------------------- -->

We can combine the ideas of hypothesis testing with a model. Using a model, we can express our hypotheses in terms of the model parameters. For instance, if we were interested in whether $X$ has an affect on $Y$, we might set up a model:

$$Y_i = \beta X_i + \epsilon_i$$

With the hypotheses:

$$\text{H0}: \beta = 0$$

$$\text{HA}: \beta \neq 0$$

In this case, we're testing for whether $X$ has a significant effect on $Y$. Let's apply this idea to relating the variables `univ_GPA` and `high_GPA`. Luckily R has built-in tools to construct a confidence interval on the $\beta$'s in a regression [1]; we'll simply use those tools rather than do it by hand.

### __q6__ Fit a linear model predicting `univ_GPA` with the predictor `both_SAT`. Assess the model to determine how effective a predictor `both_SAT` is for `univ_GPA`. Interpret the resulting confidence interval for the coefficient on `both_SAT`.

```{r q6-task}
## TODO: Fit a model of univ_GPA on the predictor both_SAT
fit_basic <- lm(df_composite$univ_GPA ~ df_composite$both_SAT)

## NOTE: The following computes confidence intervals on regression coefficients
fit_basic %>%
  tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
```

**Observations**:

- What is the confidence interval on the coefficient of `both_SAT`? Is this coefficient significantly different from zero?
  - The confidence interval on the coefficient of both_SAT is 0.00198 to 0.00349. The coefficient is significantly different from zero as zero is not in the confidence interval.
- By itself, how well does `both_SAT` predict `univ_GPA`?
  - There is a weak positive correlation between both_SAT and univ_GPA but it does not predict univ_GPA that well.

Remember from `e-model03-interp-warnings` that there are challenges with interpreting regression coefficients! Let's investigate that idea further.

### __q7__ Fit a model predicting `univ_GPA` using both `high_GPA` and `both_SAT`. Compare the prediction accuracy and hypothesis test results.

```{r q7-task}
## TODO: Fit and assess models with predictors both_SAT + high_GPA, and high_GPA alone
fit_both_sat_and_high_GPA <-
  df_composite %>%
  lm(formula = univ_GPA ~ high_GPA + both_SAT)

## NOTE: The following computes confidence intervals on regression coefficients
fit_both_sat_and_high_GPA %>%
  tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
```

```{r}
## TODO: Fit and assess models with predictors both_SAT + high_GPA, and high_GPA alone
fit_high_GPA <-
  df_composite %>%
  lm(formula = univ_GPA ~ high_GPA)

## NOTE: The following computes confidence intervals on regression coefficients
fit_high_GPA %>%
  tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
```


**Observations**:

- How well do these models perform, compared to the one you built in q6?
  - A model with high GPA alone is the best predictor of university GPA with the confidence interval of the coefficient on the high_GPA between 0.535 and 0.815. The confidence interval for the coefficient of high_GPA decreases when both_SAT is included in the model, indicating that the best model for predicting university GPA is high GPA alone.
- What is the confidence interval on the coefficient of `both_SAT` when including `high_GPA` as a predictor?? Is this coefficient significantly different from zero?
  - The confidence interval on the coefficient of both_SAT when including high_GPA as a predictor is -0.0002 to 0.0018. It is not significantly different from zero.
- How do the hypothesis test results compare with the results in q6?
  - We can confidently reject the null hypothesis, and conclude that high_GPA has an effect on university GPA. We can also conclude that high_GPA more strongly predicts university GPA than both_SAT.

## Synthesize
<!-- ------------------------- -->

Before closing, let's synthesize a bit from the analyses above.

### __q8__ Using the results from all previous q's, answer the following questions.

**Observations**:

- Between `both_SAT` and `high_GPA`, which single variable would you choose to predict `univ_GPA`? Why?
  - I would choose high school GPA as (q7 shows) it is a much stronger predictor of university GPA than both_SAT alone, or both_SAT and high_GPA combined.
- Is `both_SAT` an effective predictor of `univ_GPA`? What specific pieces of evidence do you have in favor of `both_SAT` being effective? What specific pieces of evidence do you have against?
  - both_SAT does affect univ_GPA but is a very weak predictor. Evidence in favor of both_SAT being effective: the coefficient on both_SAT with the linear model between both_SAT and univ_GPA is significantly nonzero. Evidence against both_SAT being effective: the coefficient on both_SAT with the linear model between both_SAT and univ_GPA is very close to zero, and when high_GPA is added into the model, the coefficient on both_SAT is not significantly nonzero - in other words, in that model with high_GPA introduced, we cannot confidently conclude that both_SAT has any effect on univ_GPA.

# End Notes
<!-- ----------------------------------------------------------------------- -->

[1] There are also assumptions underlying this kind of testing, for more information see this [Wiki article](https://en.wikipedia.org/wiki/Linear_regression#Assumptions).
